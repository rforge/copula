<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>R: Elements of Copula Modeling with R</title>

    <link rel="icon" type="image/png" href="./contents/favicon-32x32.png" sizes="32x32" />
    <link rel="icon" type="image/png" href="./contents/favicon-16x16.png" sizes="16x16" />

    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/R.css" rel="stylesheet">
  </head>
  <body>
    <div class="container page">
      <div class="row">
        <div class="col-xs-12 col-sm-offset-1 col-sm-2 sidebar" role="navigation">
<div class="row">
<div class="col-xs-6 col-sm-12">
<p><a href="/"><img src = "./contents/R_logo.png" width = "100" height = "78" alt = "R" /></a></p>
<h2 id="overview">Overview</h2>
<ul>
<li><a href="index.html">Home</a></li>
<li><a href="features.html">Features</a></li>
<li><a href="cite.html">Citation</a></li>
<li><a href="errata.html">Errata</a></li>
<li><a href="bugs.html">Bugs</a></li>
</ul>
<h2 id="r-code">R code</h2>
<ul>
<li><a href="02_copulas.html">Chapter 2</a></li>
<li><a href="03_classes.html">Chapter 3</a></li>
<li><a href="04_fitting.html">Chapter 4</a></li>
<li><a href="05_gof.html">Chapter 5</a></li>
<li><a href="06_misc.html">Chapter 6</a></li>
</ul>
</div>
</div>
        </div>
        <div class="col-xs-12 col-sm-7">
        <h1>Elements of Copula Modeling with R</h1>
<h2 id="code-from-chapter-5">Code from Chapter 5</h2>
<p>Below is the R code from Chapter 5 of the book “Elements of Copula Modeling with R”. The code is also available as an <a href="R/05_gof.R">R script</a>. Please <a href="cite.html">cite</a> the book or package when using the code; in particular, in publications.</p>
<pre><code>## By Marius Hofert, Ivan Kojadinovic, Martin Maechler, Jun Yan

## R script for Chapter 5 of Elements of Copula Modeling with R


### 5.1 Basic graphical diagnostics ############################################

### Pseudo-observations and normal scores

data(danube, package = &quot;lcopula&quot;)
U &lt;- as.matrix(danube)
plot(U, xlab = &quot;Donau&quot;, ylab = &quot;Inn&quot;)
plot(qnorm(U), xlab = &quot;Donau&quot;, ylab = &quot;Inn&quot;)


### Comparing (non-)parametric estimates of the copula

## Fit a Gumbel-Hougaard copula and compute the contours
fg &lt;- fitCopula(gumbelCopula(), data = U)
cpG &lt;- contourplot2(fg@copula, FUN = pCopula, region = FALSE,
                    key = list(corner = c(0.04, 0.04),
                               lines = list(col = 1:2, lwd = 2),
                               text = list(c(&quot;Fitted Gumbel-Hougaard copula&quot;,
                                             &quot;Empirical copula&quot;))))
## Fit a Joe copula and compute the contours
fj &lt;- fitCopula(joeCopula(), data = U)
cpJ &lt;- contourplot2(fj@copula, FUN = pCopula, region = FALSE,
                    key = list(corner = c(0.04, 0.04),
                               lines = list(col = 1:2, lwd = 2),
                               text = list(c(&quot;Fitted Joe copula&quot;,
                                             &quot;Empirical copula&quot;))))
## Compute the contours of the empirical copula
u &lt;- seq(0, 1, length.out = 16)
grid &lt;- as.matrix(expand.grid(u1 = u, u2 = u))
val &lt;- cbind(grid, z = C.n(grid, X = U))
cpCn &lt;- contourplot2(val, region = FALSE, labels = FALSE, col = 2)
## Plots (lattice objects)
library(latticeExtra)
cpG + cpCn
cpJ + cpCn

(fk &lt;- fitCopula(khoudrajiCopula(copula2 = gumbelCopula()), data = U,
                 start = c(1.1, 0.5, 0.5), optim.method = &quot;Nelder-Mead&quot;))

(fk2 &lt;- fitCopula(khoudrajiCopula(copula2 = gumbelCopula(),
                                  shapes = fixParam(c(NA_real_, 1),
                                                    c(FALSE, TRUE))),
                  data = U, start = c(1.1, 0.5)))

cpK &lt;- contourplot2(fk2@copula, FUN = pCopula, region = FALSE,
                    key = list(corner = c(0.04, 0.04),
                               lines = list(col = 1:2, lty = 1),
                               text = list(c(&quot;Fitted Khoudraji-Gumbel-Hougaard copula&quot;,
                                             &quot;Empirical copula&quot;))))
cpK + cpCn


### Comparing (non-)parametric estimates of the Pickands dependence function

curve(A(fg@copula, x), from = 0, to = 1, ylim = c(0.5, 1),
      lwd = 2, xlab = &quot;t&quot;, ylab = &quot;A(t)&quot;, col = 1) # parametric
curve(A(fk2@copula, x), 0,1, lwd = 2, add = TRUE, col = 2) # parametric
curve(An.biv(U, x),     0,1, lwd = 2, add = TRUE, col = 3) # non-parametric
lines(c(0, 0.5, 1), c(1, 0.5, 1), lty = 2)
lines(c(0, 1),      c(1, 1),      lty = 2)
legend(&quot;bottomright&quot;, bty = &quot;n&quot;, lwd = 2, col=1:3,
       legend = expression({A[theta[n]]^{GH}}(t),
                           {A[bold(theta)[n]]^{KGH}}(t),
                           {A[list(n,c)]^{CFG}}(t)),
       inset = 0.02, y.intersp = 1.2)


### 5.2 Hypothesis tests #######################################################

### 5.2.1 Tests of independence ################################################

### Test of uncorrelatedness

data(danube, package = &quot;lcopula&quot;)
cor.test(danube[,1], danube[,2], method = &quot;kendall&quot;)


### A fallacy of a test of uncorrelatedness

set.seed(1515)
x &lt;- rnorm(200)
y &lt;- x^2
cor.test(x, y, method = &quot;kendall&quot;)


### Test of independence based on S_n^Pi

n &lt;- 100
d &lt;- 3
set.seed(1969)
U &lt;- rCopula(n, frankCopula(2, dim = d))

dist &lt;- indepTestSim(n, p = d, verbose = FALSE)
indepTest(U, d = dist)


### 5.2.2 Tests of exchangeability #############################################

### Test of exchangeability based on S_n^{ex_C}

set.seed(1453)
exchTest(as.matrix(danube))


### Test of exchangeability based on S_n^{ex_A}

withTime &lt;- function(expr, ...)
{
    st &lt;- system.time(r &lt;- expr, ...)
    list(value = r,  sys.time = st)
}

set.seed(1492)
withTime(exchEVTest(as.matrix(danube)))


### 5.2.3 A test of radial symmetry ############################################

### Test of radial symmetry based on S_n^sym

set.seed(1453)
withTime(radSymTest(as.matrix(danube)))

data(rdj)
Xrdj &lt;- as.matrix(rdj[,-1]) # omitting component &#39;Date&#39;
set.seed(1389)
withTime(radSymTest(Xrdj))


### 5.2.4 Tests of extreme-value dependence ####################################

### Test of extreme-value dependence based on S_n^{ev_K}

set.seed(1805)
evTestK(as.matrix(danube))


### Test of extreme-value dependence based on S_n^{ev_A}

set.seed(1815)
withTime(evTestA(as.matrix(danube)))


### Test of extreme-value dependence based on S_n^{ev_C}

set.seed(1905)
withTime(evTestC(Xrdj))


### 5.2.5 Goodness-of-fit tests ################################################

### Parametric bootstrap-based tests

set.seed(1598)
withTime(gofCopula(claytonCopula(dim = 3), x = Xrdj, optim.method=&quot;BFGS&quot;))


### Multiplier goodness-of-fit tests

set.seed(1610)
withTime(gofCopula(claytonCopula(dim = 3), x = Xrdj, simulation = &quot;mult&quot;))

set.seed(1685)
gofCopula(normalCopula(dim = 3, dispstr = &quot;un&quot;), x = Xrdj,
          simulation = &quot;mult&quot;)

set.seed(1792)
gofCopula(tCopula(dim = 3, dispstr = &quot;un&quot;, df.fixed = TRUE, df = 10),
          x = Xrdj, simulation = &quot;mult&quot;)


### Empirical levels of the multiplier goodness-of-fit test for the Joe family

theta &lt;- iTau(joeCopula(), tau = 0.5) # Joe copula parameter
##&#39; @title P-value of multiplier goodness-of-fit test on data
##&#39;        generated under the null hypothesis
##&#39; @param n sample size
##&#39; @param theta Joe copula parameter
##&#39; @return p-value of the multiplier goodness-of-fit test
pvalMult &lt;- function(n, theta)
{
    U &lt;- rCopula(n, copula = joeCopula(theta))
    gofCopula(joeCopula(), x = pobs(U), simulation = &quot;mult&quot;,
              optim.method = &quot;BFGS&quot;)$p.value
}

set.seed(1940)
pv &lt;- withTime(replicate(1000, pvalMult(n = 100, theta = theta)))

pv$sys.time # the run time

alpha &lt;- c(0.01, 0.05, 0.1) # nominal levels
rbind(nom.level = alpha, emp.level = ecdf(pv$value)(alpha)) # levels


### Goodness-of-fit tests based on method-of-moments estimation

Xd &lt;- as.matrix(danube)
set.seed(1613)
gofCopula(gumbelCopula(), x = Xd, estim.method = &quot;itau&quot;)

set.seed(1914)
gofCopula(gumbelCopula(), x = Xd, estim.method = &quot;itau&quot;,
          simulation = &quot;mult&quot;)

set.seed(1848)
gofCopula(joeCopula(), x = Xd, estim.method = &quot;itau&quot;)


### Goodness of fit of the Khoudraji-Gumbel-Hougaard family

set.seed(1969) ## Parametric bootstrap-based test
withTime(
    gofCopula(khoudrajiCopula(copula2 = gumbelCopula(),
                          shapes = fixParam(c(NA_real_, 1), c(FALSE, TRUE))),
              start = c(1.1, 0.5), x = Xd, optim.method = &quot;Nelder-Mead&quot;)
)

set.seed(1969) ## Multiplier-based test
withTime(
    gofCopula(khoudrajiCopula(copula2 = gumbelCopula(),
                          shapes = fixParam(c(NA_real_, 1), c(FALSE, TRUE))),
              start = c(1.1, 0.5), x = Xd, optim.method = &quot;Nelder-Mead&quot;,
              simulation = &quot;mult&quot;)
)


### 5.2.6 A mixture of graphical and formal goodness-of-fit tests ##############

### A mixture of graphical and formal goodness-of-fit tests

## Load the data, compute the log-returns and the pseudo-observations
data(SMI.12) # load the SMI constituent data
library(qrmtools)
X &lt;- returns(SMI.12) # compute log-returns
U &lt;- pobs(X) # compute pseudo-observations
d &lt;- ncol(U) # 20 dimensions

fit &lt;- fitCopula(tCopula(dim = d, dispstr = &quot;un&quot;), data = U,
                 method = &quot;itau.mpl&quot;)
## Extract parameter estimates
len &lt;- length(fit@estimate)
stopifnot(len == d*(d-1)/2 + 1) # sanity check
p &lt;- fit@estimate[seq_len(len-1)] # correlations
## Note: The estimated correlation matrix can be obtained via p2P(p, d = d)
nu &lt;- fit@estimate[len] # degrees of freedom nu

## Define the H_0 copula
cop.t &lt;- ellipCopula(&quot;t&quot;, df = nu, param = p, dim = d, dispstr = &quot;un&quot;)
## Build the array of pairwise H_0-transformed data columns
cu.u.t &lt;- pairwiseCcop(U, cop.t, df = nu)
## Compute pairwise matrix (d by d) of p-values and corresponding colors
set.seed(1389) # for reproducibility
pw.indep.t &lt;- pairwiseIndepTest(cu.u.t, N = 256, verbose = FALSE)
p.val.t &lt;- pviTest(pw.indep.t) # matrix of p-values
## Pairwise Rosenblatt plot (test for the fitted t copula)
title &lt;- list(&quot;Pairwise Rosenblatt transformed pseudo-observations&quot;,
              quote(bold(&quot;to test&quot;)~~italic(H[0]:C)~~&quot;is&quot;~~italic(t)))
cols &lt;- gray(seq(0.1, 1, length.out = 6))
pairsRosenblatt(cu.u.t, pvalueMat = p.val.t, method = &quot;QQchisq&quot;, pch=&quot;.&quot;,
                xaxt = &quot;n&quot;, yaxt = &quot;n&quot;,
                colList = pairsColList(p.val.t, bucketCols = cols,
                                       BWcutoff = 0),
                main.centered = TRUE, main = title, line.main = c(2, -0.8))


### 5.3 Model selection ########################################################

### Cross-validation for the danube data set

Xdan &lt;- as.matrix(danube)
withTime(xvCopula(joeCopula(), x = Xdan))

withTime(xvCopula(gumbelCopula(), x = Xdan))

withTime(
    xvCopula(khoudrajiCopula(copula2 = gumbelCopula(),
                             shapes = fixParam(c(NA_real_, 1),
                                               c(FALSE, TRUE))),
             x = Xdan, start = c(1.1, 0.5), optim.method = &quot;Nelder-Mead&quot;)
)

k &lt;- 50
set.seed(7)
withTime(xvCopula(joeCopula(), x = Xdan, k = k))

set.seed(13)
withTime(xvCopula(gumbelCopula(), x = Xdan, k = k))

set.seed(14)
withTime(
    xvCopula(khoudrajiCopula(copula2 = gumbelCopula(),
                             shapes = fixParam(c(NA_real_, 1),
                                               c(FALSE, TRUE))),
             x = Xdan, k = k, start = c(1.1, 0.5),
             optim.method = &quot;Nelder-Mead&quot;)
)


### Cross-validation for the rdj data set

withTime(xvCopula(normalCopula(dim = 3, dispstr = &quot;un&quot;), x = Xrdj))

withTime(xvCopula(tCopula(dim = 3, dispstr = &quot;un&quot;, df = 10, df.fixed = TRUE),
                  x = Xrdj))

set.seed(22)
withTime(xvCopula(normalCopula(dim = 3, dispstr = &quot;un&quot;), x = Xrdj, k = k))

set.seed(4)
withTime(xvCopula(tCopula(dim = 3, dispstr = &quot;un&quot;, df = 10, df.fixed = TRUE),
                  x = Xrdj, k = k))

set.seed(1980)
withTime(xvCopula(tCopula(dim = 3, dispstr = &quot;un&quot;), x = Xrdj, k = k))

summary(fitCopula(tCopula(dim = 3, dispstr = &quot;un&quot;), data = pobs(Xrdj)))

</code></pre>
        </div>
      </div>
      <div class="raw footer">
        &copy; Marius Hofert, Ivan Kojadinovic, Martin Mächler, Jun Yan
      </div>
    </div>
  </body>
</html>
